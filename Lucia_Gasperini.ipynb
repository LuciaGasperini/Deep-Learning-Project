{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Next frame prediction\n",
        "\n",
        "Name and ID: Lucia Gasperini 0001092234"
      ],
      "metadata": {
        "id": "OIFPRLd0P3Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Description of the task\n",
        "The project consists of predicting the next frame in a short movie sequence.\n",
        "\n",
        "For this project, we shall use the Moving MNIST dataset, composed of 10,000 video sequences, each consisting of 20 frames. In each video sequence, two digits move independently around the frame, which has a spatial resolution of 64×64 pixels. The digits frequently intersect with each other and bounce off the edges of the frame.\n",
        "\n",
        "While each sequence has a lenght of 20, your are supposed to use **only 3 consecutive frames as input**, and **predict the next one**.\n",
        "\n",
        "The metric used to evaluate the quality of the predicted frame is Mean Squared Error."
      ],
      "metadata": {
        "id": "v85Qq_p0my49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution approach"
      ],
      "metadata": {
        "id": "azXJ8atGu0yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute a valid solution, I've decided to adopt a model which makes use of the ConvLSTM architecture (Convolutional Long Short-Term Memory) neural network model for processing spatiotemporal data."
      ],
      "metadata": {
        "id": "d2U1pOGEutY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing relevant Libraries"
      ],
      "metadata": {
        "id": "Pv6OOLhU_14T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Wlg8ZSz3FHFh",
        "execution": {
          "iopub.status.busy": "2023-07-09T18:11:05.480120Z",
          "iopub.execute_input": "2023-07-09T18:11:05.480507Z",
          "iopub.status.idle": "2023-07-09T18:11:05.485715Z",
          "shell.execute_reply.started": "2023-07-09T18:11:05.480480Z",
          "shell.execute_reply": "2023-07-09T18:11:05.484509Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Construction"
      ],
      "metadata": {
        "id": "icwRHlmoBB7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Moving MNIST dataset\n",
        "ds = tfds.as_numpy(tfds.load(\n",
        "    'moving_mnist',\n",
        "    split='test',\n",
        "    batch_size=-1\n",
        "))\n",
        "sequences = ds['image_sequence']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e7cd7d388bd74afb8ee71a1e0290f624",
            "04e3cf37aafd495d9297ed2240085bf0",
            ""
          ]
        },
        "id": "0nyzhFRDVuFw",
        "outputId": "3eeecc12-b110-4b5a-d4ff-e049c05a68d6",
        "execution": {
          "iopub.status.busy": "2023-07-09T18:11:08.401079Z",
          "iopub.execute_input": "2023-07-09T18:11:08.401449Z",
          "iopub.status.idle": "2023-07-09T18:13:44.629411Z",
          "shell.execute_reply.started": "2023-07-09T18:11:08.401420Z",
          "shell.execute_reply": "2023-07-09T18:13:44.628413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: 91.70 MiB, total: 91.70 MiB) to /root/tensorflow_datasets/moving_mnist/1.0.0...\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7cd7d388bd74afb8ee71a1e0290f624"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04e3cf37aafd495d9297ed2240085bf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Shuffling /root/tensorflow_datasets/moving_mnist/1.0.0.incompleteYK8CGC/moving_mnist-test.tfrecord*...:   0%| …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\u001b[1mDataset moving_mnist downloaded and prepared to /root/tensorflow_datasets/moving_mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of 10000 sequences of 20 frames each. Each (grayscale) frame has dimension 64x64"
      ],
      "metadata": {
        "id": "JXFR88VToaSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the PREPROCESSING I have removed the squeezing and the swapping of the axis because LSTM architecture needs the 5 dimension (for this reason I have also change the dimensions and the order of the parameters in the image_generator function)."
      ],
      "metadata": {
        "id": "mUQKHOJgkP2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Swap the axes representing the number of frames and number of data samples\n",
        "#sequences = np.squeeze(np.swapaxes(sequences, 1, 4),axis=1)/255.\n",
        "\n",
        "sequences = sequences/255.\n",
        "print(sequences.shape)\n",
        "print(np.min(sequences),np.max(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkS8Z9bXVxVG",
        "outputId": "90f734a8-0a4b-4f9b-9d70-1e72260a0f46",
        "execution": {
          "iopub.status.busy": "2023-07-09T18:13:44.631448Z",
          "iopub.execute_input": "2023-07-09T18:13:44.631787Z",
          "iopub.status.idle": "2023-07-09T18:13:48.925010Z",
          "shell.execute_reply.started": "2023-07-09T18:13:44.631754Z",
          "shell.execute_reply": "2023-07-09T18:13:48.924012Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(10000, 20, 64, 64, 1)\n0.0 1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset in training, validation and testing."
      ],
      "metadata": {
        "id": "xEJxqJ0SotTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = sequences[:8000]\n",
        "valset = sequences[8000:9000]\n",
        "testset = sequences[9000:10000]\n",
        "print(testset.shape, trainset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSAjVd9bYhl",
        "outputId": "dc1a439b-76f5-40de-94d5-8fc005469b24",
        "execution": {
          "iopub.status.busy": "2023-07-09T18:13:48.926520Z",
          "iopub.execute_input": "2023-07-09T18:13:48.927527Z",
          "iopub.status.idle": "2023-07-09T18:13:48.934847Z",
          "shell.execute_reply.started": "2023-07-09T18:13:48.927490Z",
          "shell.execute_reply": "2023-07-09T18:13:48.933718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1000, 20, 64, 64, 1) (8000, 20, 64, 64, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n"
      ],
      "metadata": {
        "id": "HywEAd2sE8yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a simple generator, creating the input sequences of 3 frames, and the expected output, namely the next frame.\n",
        "\n",
        "Due to the changing in the preprocessing I have also changed the order of the values of batch_x and batch_y and I have added a fifth dimension."
      ],
      "metadata": {
        "id": "Ro84EIPjpCDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_generator(dataset,batchsize=16,seqlen=4):\n",
        "    while True:\n",
        "      # Initialize empty arrays for the batch inputs and targets\n",
        "      batch_x = np.zeros((batchsize,seqlen-1,64,64,1))\n",
        "      batch_y = np.zeros((batchsize,1,64,64,1))\n",
        "      ran = np.random.randint(dataset.shape[0],size=batchsize)\n",
        "\n",
        "      # Randomly select indices from the dataset\n",
        "      minibatch = dataset[ran]\n",
        "      #these sequences have length 20; we reduce them to seqlen\n",
        "\n",
        "      # Iterate over the selected batch indices\n",
        "      for i in range(batchsize):\n",
        "          # Randomly choose a start index for the sequence\n",
        "          random_start = np.random.randint(0,20-seqlen)\n",
        "          random_end = random_start+seqlen-1\n",
        "\n",
        "          # Fill the batch input and target arrays with the selected sequence\n",
        "          batch_x[i,:,:,:,0] = minibatch[i,random_start:random_end,:,:,0]\n",
        "          batch_y[i,:,:,:,0] = minibatch[i,random_end:random_end+1,:,:,0]\n",
        "\n",
        "      # Yield the batch inputs and targets\n",
        "      yield(batch_x,batch_y)"
      ],
      "metadata": {
        "id": "ZzzBAxNwKOGt",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:25.666944Z",
          "iopub.execute_input": "2023-07-09T21:06:25.667392Z",
          "iopub.status.idle": "2023-07-09T21:06:25.677018Z",
          "shell.execute_reply.started": "2023-07-09T21:06:25.667357Z",
          "shell.execute_reply": "2023-07-09T21:06:25.675761Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prova_gen = image_generator(testset,batchsize=1,seqlen=4)"
      ],
      "metadata": {
        "id": "1i9wGAY0fl1C",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:30.427978Z",
          "iopub.execute_input": "2023-07-09T21:06:30.428553Z",
          "iopub.status.idle": "2023-07-09T21:06:30.433468Z",
          "shell.execute_reply.started": "2023-07-09T21:06:30.428523Z",
          "shell.execute_reply": "2023-07-09T21:06:30.432272Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x, sample_y = next(prova_gen)\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7n5_ZMvf1Xe",
        "outputId": "8ebdbf17-6735-40f3-ac01-738ceaad090c",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:33.822169Z",
          "iopub.execute_input": "2023-07-09T21:06:33.822848Z",
          "iopub.status.idle": "2023-07-09T21:06:33.829090Z",
          "shell.execute_reply.started": "2023-07-09T21:06:33.822811Z",
          "shell.execute_reply": "2023-07-09T21:06:33.828113Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1, 3, 64, 64, 1) (1, 1, 64, 64, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sample_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAtcBioVkd89",
        "outputId": "cb6339de-12d7-4f16-aa2a-f02031a15c9d",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:36.919087Z",
          "iopub.execute_input": "2023-07-09T21:06:36.919457Z",
          "iopub.status.idle": "2023-07-09T21:06:36.924743Z",
          "shell.execute_reply.started": "2023-07-09T21:06:36.919428Z",
          "shell.execute_reply": "2023-07-09T21:06:36.923552Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'numpy.ndarray'>\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_list(images): #takes in input a list of images and plot them\n",
        "    # Calculate the number of images in the list\n",
        "    size = len(images)\n",
        "\n",
        "    # Set the figure size based on the number of images\n",
        "    plt.figure(figsize=(10, 10 * size))\n",
        "\n",
        "    # Iterate over the images and plot them\n",
        "    for i in range(size):\n",
        "        plt.subplot(1, size, i + 1)\n",
        "        plt.imshow(images[i],cmap='gray',)\n",
        "\n",
        "    # Turn off the axis labels\n",
        "    plt.axis(\"off\")\n",
        "    # Adjust the spacing between subplots\n",
        "    plt.tight_layout()\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "    # Close the figure to release memory resources\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "l98wOX0vbvpu",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:39.690221Z",
          "iopub.execute_input": "2023-07-09T21:06:39.690934Z",
          "iopub.status.idle": "2023-07-09T21:06:39.700028Z",
          "shell.execute_reply.started": "2023-07-09T21:06:39.690904Z",
          "shell.execute_reply": "2023-07-09T21:06:39.699064Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all = [sample_x[0,i,:,:,0] for i in range(3)]+[sample_y[0,0,:,:,0]]\n",
        "show_list(all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "fxbKLeribyps",
        "outputId": "7c993284-6117-4000-8cec-a23f265c41f1",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:44.031520Z",
          "iopub.execute_input": "2023-07-09T21:06:44.031877Z",
          "iopub.status.idle": "2023-07-09T21:06:44.608321Z",
          "shell.execute_reply.started": "2023-07-09T21:06:44.031850Z",
          "shell.execute_reply": "2023-07-09T21:06:44.607415Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x4000 with 4 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = image_generator(trainset)\n",
        "val_gen = image_generator(valset)\n",
        "test_gen = image_generator(testset)"
      ],
      "metadata": {
        "id": "ZedwxykwK_8D",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:48.468802Z",
          "iopub.execute_input": "2023-07-09T21:06:48.469156Z",
          "iopub.status.idle": "2023-07-09T21:06:48.475955Z",
          "shell.execute_reply.started": "2023-07-09T21:06:48.469127Z",
          "shell.execute_reply": "2023-07-09T21:06:48.474970Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x, sample_y = next(train_gen)"
      ],
      "metadata": {
        "id": "PXIoWhFvL6uK",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:50.153250Z",
          "iopub.execute_input": "2023-07-09T21:06:50.153630Z",
          "iopub.status.idle": "2023-07-09T21:06:50.162418Z",
          "shell.execute_reply.started": "2023-07-09T21:06:50.153602Z",
          "shell.execute_reply": "2023-07-09T21:06:50.161262Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Construction\n",
        "\n",
        "LSTM (Long Short Term Memory) is a Recurrent Neural Network architecture. In this kind of architecture, the model passes the previous hidden state to the next step of the sequence. Therefore holding information on previous data the network has seen before and using it to make decisions. In other words, the data order is extremely important.\n",
        "In this case, with sequencial images, one approach is using ConvLSTM layers. It is a Recurrent layer, just like the LSTM, but internal matrix multiplications are exchanged with convolution operations.\n",
        "\n",
        "To build a Convolutional LSTM model, I will use the ConvLSTM2D layer, which will accept inputs of shape (batch_size, num_frames, width, height, channels), and return a prediction movie of the same shape."
      ],
      "metadata": {
        "id": "Qe3Ce-dbIV9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = image_generator(trainset)\n",
        "val_gen = image_generator(valset)\n",
        "test_gen = image_generator(testset)\n",
        "\n",
        "print(next(train_gen)[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImkLoFztXUgi",
        "outputId": "fac46ee7-5f83-4261-baeb-9b3bc68f8e94",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:53.508246Z",
          "iopub.execute_input": "2023-07-09T21:06:53.508642Z",
          "iopub.status.idle": "2023-07-09T21:06:53.518316Z",
          "shell.execute_reply.started": "2023-07-09T21:06:53.508612Z",
          "shell.execute_reply": "2023-07-09T21:06:53.517091Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(16, 3, 64, 64, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture I have decided to use consists of multiple `ConvLSTM2D` layers with batch normalization and a final `Conv3D` layer for spatiotemporal data processing. Each ConvLSTM2D layer processes spatiotemporal data and captures temporal dependencies between frames, while the batch normalization layers help with normalization and regularization (better convergence during training). I have decided, after sever trial to use four ConvLSTM2D layers applied successively with increasing complexity."
      ],
      "metadata": {
        "id": "R37mxS7qoDMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (None, 64, 64, 1)\n",
        "\n",
        "# Input layer\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "# First ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(7, 7),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Second ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(5, 5),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Third ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(3, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Fourth ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(3, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Fifth ConvLSTM2D layer\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(1, 1),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "\n",
        "# Conv3D layer for spatiotemporal outputs\n",
        "x = layers.Conv3D(\n",
        "    filters=1,\n",
        "    kernel_size=(3, 3, 3),\n",
        "    activation=\"sigmoid\",\n",
        "    padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "# Lambda layer to select the last frame of each sequence\n",
        "x = layers.Lambda(lambda x: x[:, -1, :, :, :])(x)\n",
        "\n",
        "# Reshape layer to adjust the shape of the tensor\n",
        "output = layers.Reshape((1, 64, 64, 1))(x)\n",
        "\n",
        "# Create the model\n",
        "model = keras.models.Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "GpzDzipQRgG6",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:06:57.779744Z",
          "iopub.execute_input": "2023-07-09T21:06:57.780805Z",
          "iopub.status.idle": "2023-07-09T21:06:58.522225Z",
          "shell.execute_reply.started": "2023-07-09T21:06:57.780760Z",
          "shell.execute_reply": "2023-07-09T21:06:58.521306Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As kernel size for first layer I tried both 7x7 and 9x9, before the 5x5. The best result was obtained with 7x7, since, a 9x9 kernel has a larger convolution window (it can capture larger spatial features in the input data) than a 7x7 kernel (it may allow to capture finer details in the images). Each additional layer allows the model to learn and extract higher-level features from the input. I have tried this model with several combination of the kernel size (some combination are listed in the last section of this notebook).\n",
        "\n",
        "The model I have decided to use consists of several layers:\n",
        "- The input shape is defined as (None, 64, 64, 1), indicating a variable-length sequence of 2D images with a size of 64x64 pixels and a single channel. The input layer is created using the defined input shape.\n",
        "\n",
        "- The first layer is a ConvLSTM2D\n",
        "layer with 64 filters, a kernel size of (7, 7), and \"same\" padding (to keep the output size the same as the input). It returns sequences True, meaning it preserves the temporal dimension (to return the output for each time step in the sequence). The activation function is ReLU. It takes input with shape (None, 64, 64, 1), where None represents a variable-length sequence of 2D images with a size of 64x64 and a single channel (grayscale).\n",
        "\n",
        "- After the ConvLSTM2D layer, there is a BatchNormalization layer. It normalizes the activations of the previous layer along the batch dimension. It helps mitigate covariate shift issues and speeds up model training.\n",
        "\n",
        "- The second layer is another ConvLSTM2D layer with 64 filters, a kernel size of (5, 5), and \"same\" padding. It also returns sequences and uses the ReLU activation function.\n",
        "\n",
        "- Another BatchNormalization layer follows the second ConvLSTM2D layer.\n",
        "\n",
        "- The third ConvLSTM2D layer also follows a similar structure, but with a smaller 3x3 kernel size.\n",
        "\n",
        "- Another BatchNormalization layer follows the Third ConvLSTM2D layer.\n",
        "\n",
        "- The fourth ConvLSTM2D layer is another 3x3 kernel size. The addition of an additional 3x3 layer in this network aims to introduce another convolution operation to extract more complex features and further refine the data representation. In the specified network, the ConvLSTM2D layers are used to model spatiotemporal relationships within the input data. Each ConvLSTM2D layer uses a specific-sized kernel to perform spatial and temporal convolution operations on the input data. Adding an additional 3x3 layer allows the network to perform another convolution operation to further refine the representation of the features extracted by the previous layers, improving the network's ability to capture meaningful information in the input data and enhance the overall performance of the model. The early layers tend to extract basic features such as edges and lines, while the subsequent layers combine these basic features to recognize more complex shapes and spatiotemporal structures.\n",
        "\n",
        "- Another BatchNormalization layer follows the fourth ConvLSTM2D layer.\n",
        "\n",
        "- The fifth layer is a ConvLSTM2D layer similar to the previous one but with a kernel size of (1, 1), which means it operates on a single frame in the sequence and acts as a spatial attention mechanism. This layer helps refine the features learned by previous layers.\n",
        "\n",
        "- Finally, there is a Conv3D layer (used for spatiotemporal outputs)with a kernel size of (3, 3, 3). It has a single filter and uses the sigmoid activation function. The Conv3D layer performs three-dimensional convolution on its input. It applies a set of filters to a 3D input volume, which can be thought of as a sequence of 2D images over time. The purpose of this layer is to extract spatiotemporal features from the input data.\n",
        "\n",
        "- A Lambda layer is added to extract the final frame of the sequence. It selects the last frame along the time dimension. The lambda function x[:,-1,:,:,:] selects the last frame along the time dimension, discarding earlier frames.\n",
        "\n",
        "- A Reshape layer is added to change the shape of the output tensor to (1, 64, 64, 1). This reshaping might be necessary depending on the requirements of the subsequent layers or the desired output shape.\n",
        "\n",
        "- In the end, a model is created with the defined inputs and outputs using the Model class from Keras.\n",
        "\n",
        "Without the Lambda and the reshape layer I have obtained an higher MSE because the first two frame generated by the Conv3D are not so good and make the result worse.\n",
        "\n",
        "These layers together form the model architecture that processes spatiotemporal data using ConvLSTM and Conv3D layers, selecting the last frame of each sequence and adjusting the tensor shape as needed. The model takes 5D input with shape (batch_size, timesteps, width, height, channels) and produces a 5D output with shape (batch_size, timesteps, height, width, 1)."
      ],
      "metadata": {
        "id": "8RI8Z6ITpIhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abENAXntYkaI",
        "outputId": "a34f7361-a849-4990-c7ec-76a801e407a8",
        "execution": {
          "iopub.status.busy": "2023-07-09T18:13:50.572909Z",
          "iopub.execute_input": "2023-07-09T18:13:50.573620Z",
          "iopub.status.idle": "2023-07-09T18:13:50.612597Z",
          "shell.execute_reply.started": "2023-07-09T18:13:50.573588Z",
          "shell.execute_reply": "2023-07-09T18:13:50.611870Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, None, 64, 64, 1)  0         \n                             ]                                   \n                                                                 \n conv_lstm2d (ConvLSTM2D)    (None, None, 64, 64, 64)  815616    \n                                                                 \n batch_normalization (BatchN  (None, None, 64, 64, 64)  256      \n ormalization)                                                   \n                                                                 \n conv_lstm2d_1 (ConvLSTM2D)  (None, None, 64, 64, 64)  819456    \n                                                                 \n batch_normalization_1 (Batc  (None, None, 64, 64, 64)  256      \n hNormalization)                                                 \n                                                                 \n conv_lstm2d_2 (ConvLSTM2D)  (None, None, 64, 64, 64)  295168    \n                                                                 \n batch_normalization_2 (Batc  (None, None, 64, 64, 64)  256      \n hNormalization)                                                 \n                                                                 \n conv_lstm2d_3 (ConvLSTM2D)  (None, None, 64, 64, 64)  295168    \n                                                                 \n batch_normalization_3 (Batc  (None, None, 64, 64, 64)  256      \n hNormalization)                                                 \n                                                                 \n conv_lstm2d_4 (ConvLSTM2D)  (None, None, 64, 64, 64)  33024     \n                                                                 \n conv3d (Conv3D)             (None, None, 64, 64, 1)   1729      \n                                                                 \n lambda (Lambda)             (None, 64, 64, 1)         0         \n                                                                 \n reshape (Reshape)           (None, 1, 64, 64, 1)      0         \n                                                                 \n=================================================================\nTotal params: 2,261,185\nTrainable params: 2,260,673\nNon-trainable params: 512\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.binary_crossentropy, # Binary cross-entropy loss function\n",
        "    optimizer=keras.optimizers.Adam(), # Adam optimizer\n",
        "    metrics=[keras.metrics.MeanSquaredError()] # Mean Squared Error metric\n",
        ")"
      ],
      "metadata": {
        "id": "pkv6ZS5XJtWY",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:07:11.823462Z",
          "iopub.execute_input": "2023-07-09T21:07:11.823832Z",
          "iopub.status.idle": "2023-07-09T21:07:11.841313Z",
          "shell.execute_reply.started": "2023-07-09T21:07:11.823802Z",
          "shell.execute_reply": "2023-07-09T21:07:11.840347Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code written above compiles the defined model by configuring its loss function (I have used the Binary Crossentropy), optimizer, and evaluation metrics. Once the model is compiled, it is ready for training using the fit() function with the specified loss, optimizer, and metrics settings."
      ],
      "metadata": {
        "id": "V8cvQz6lwzxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "\n",
        "With the model and data constructed, I can now train the model."
      ],
      "metadata": {
        "id": "4jKjZjsWJxYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define modifiable training hyperparameters\n",
        "epochs = 60 # Number of training epochs\n",
        "batch_size = 16 # Batch size for training"
      ],
      "metadata": {
        "id": "X5ycHyPGPiDJ",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:20:15.609867Z",
          "iopub.execute_input": "2023-07-09T21:20:15.610229Z",
          "iopub.status.idle": "2023-07-09T21:20:15.614680Z",
          "shell.execute_reply.started": "2023-07-09T21:20:15.610200Z",
          "shell.execute_reply": "2023-07-09T21:20:15.613680Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have opted for a batch size of size 16 because, after some attemps, I have noticed that in this way I have a good generalization (a batch size allows the model to see more diverse examples in each training iteration and increased  the diversity can help the model generalize better by learning from a wider range of samples within each batch)."
      ],
      "metadata": {
        "id": "rIxjDN1wnogK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After several attempts I decided to use 60 epochs (due to early stopping they are often carried out between 45 and 55 epochs since the values tend to stabilize) as it turns out to be a good compromise between efficiency and a good result. The number of epochs is sufficient to allow the model to converge to a stable and optimal solution, further training not provide significant benefits (there is minimal improvement (changes only in the third and fourth digits after the decimal point)) and could lead to overfitting (if the model starts to overfit, where the training performance continues to improve while the validation performance plateaus or starts to degrade (indication that the model has learned too much from the training data and is not generalizing well))."
      ],
      "metadata": {
        "id": "3f-r_zNMRicJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_mean_squared_error\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_mean_squared_error\", patience=5)"
      ],
      "metadata": {
        "id": "qc9hji2GylPa",
        "execution": {
          "iopub.status.busy": "2023-07-09T21:07:23.686514Z",
          "iopub.execute_input": "2023-07-09T21:07:23.687190Z",
          "iopub.status.idle": "2023-07-09T21:07:23.693543Z",
          "shell.execute_reply.started": "2023-07-09T21:07:23.687158Z",
          "shell.execute_reply": "2023-07-09T21:07:23.692344Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *early_stopping*: This line creates an EarlyStopping callback. The EarlyStopping callback monitors the val_mean_squared_error during training and stops the training process if the validation loss does not improve for a certain number of epochs specified by the patience parameter. In this case, the training will be stopped if the validation loss does not improve for 10 consecutive epochs.\n",
        "\n",
        "- *reduce_lr*: This line creates a ReduceLROnPlateau callback. The ReduceLROnPlateau callback reduces the learning rate (lr) of the optimizer when the validation loss does not improve for a certain number of epochs specified by the patience parameter. Reducing the learning rate can help the model to converge to a better solution. In this case, the learning rate will be reduced if the validation loss does not improve for 5 consecutive epochs."
      ],
      "metadata": {
        "id": "L6rmLp6Hymrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model.fit() function starts the training process with the specified parameters, including the data generators, number of epochs, batch size, and callbacks. During training, the model will iterate over the training data, compute gradients, update the model's parameters, and evaluate the performance on the validation data."
      ],
      "metadata": {
        "id": "037d-APJzkLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data.\n",
        "model.fit(\n",
        "    x=train_gen, # Training data generator\n",
        "    steps_per_epoch=len(trainset) // batch_size, # Number of steps (batches) per epoch\n",
        "    epochs=epochs, # Number of training epochs\n",
        "    validation_data=val_gen, # Validation data generator\n",
        "    validation_steps=len(valset) // batch_size, # Number of validation steps (batches)\n",
        "    callbacks=[early_stopping, reduce_lr], # List of callbacks to be used during training\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-09T18:13:50.667041Z",
          "iopub.execute_input": "2023-07-09T18:13:50.667954Z",
          "iopub.status.idle": "2023-07-09T20:57:08.954253Z",
          "shell.execute_reply.started": "2023-07-09T18:13:50.667923Z",
          "shell.execute_reply": "2023-07-09T20:57:08.953213Z"
        },
        "trusted": true,
        "id": "hDesNzc1tJLG",
        "outputId": "c3f82cbc-b310-47b9-da2c-1d575386fa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/60\n500/500 [==============================] - 245s 445ms/step - loss: 0.0813 - mean_squared_error: 0.0193 - val_loss: 0.2122 - val_mean_squared_error: 0.0323 - lr: 0.0010\nEpoch 2/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0665 - mean_squared_error: 0.0144 - val_loss: 0.0660 - val_mean_squared_error: 0.0141 - lr: 0.0010\nEpoch 3/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0627 - mean_squared_error: 0.0130 - val_loss: 0.0624 - val_mean_squared_error: 0.0128 - lr: 0.0010\nEpoch 4/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0613 - mean_squared_error: 0.0125 - val_loss: 0.0661 - val_mean_squared_error: 0.0144 - lr: 0.0010\nEpoch 5/60\n500/500 [==============================] - 222s 443ms/step - loss: 0.0603 - mean_squared_error: 0.0122 - val_loss: 0.0607 - val_mean_squared_error: 0.0122 - lr: 0.0010\nEpoch 6/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0586 - mean_squared_error: 0.0117 - val_loss: 0.0615 - val_mean_squared_error: 0.0125 - lr: 0.0010\nEpoch 7/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0586 - mean_squared_error: 0.0116 - val_loss: 0.0592 - val_mean_squared_error: 0.0117 - lr: 0.0010\nEpoch 8/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0584 - mean_squared_error: 0.0116 - val_loss: 0.0594 - val_mean_squared_error: 0.0119 - lr: 0.0010\nEpoch 9/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0577 - mean_squared_error: 0.0113 - val_loss: 0.0582 - val_mean_squared_error: 0.0115 - lr: 0.0010\nEpoch 10/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0572 - mean_squared_error: 0.0111 - val_loss: 0.0582 - val_mean_squared_error: 0.0113 - lr: 0.0010\nEpoch 11/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0572 - mean_squared_error: 0.0112 - val_loss: 0.0585 - val_mean_squared_error: 0.0115 - lr: 0.0010\nEpoch 12/60\n500/500 [==============================] - 222s 443ms/step - loss: 0.0568 - mean_squared_error: 0.0110 - val_loss: 0.0566 - val_mean_squared_error: 0.0110 - lr: 0.0010\nEpoch 13/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0562 - mean_squared_error: 0.0108 - val_loss: 0.0564 - val_mean_squared_error: 0.0108 - lr: 0.0010\nEpoch 14/60\n500/500 [==============================] - 221s 443ms/step - loss: 0.0554 - mean_squared_error: 0.0106 - val_loss: 0.0566 - val_mean_squared_error: 0.0109 - lr: 0.0010\nEpoch 15/60\n500/500 [==============================] - 222s 443ms/step - loss: 0.0559 - mean_squared_error: 0.0108 - val_loss: 0.0565 - val_mean_squared_error: 0.0109 - lr: 0.0010\nEpoch 16/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0555 - mean_squared_error: 0.0106 - val_loss: 0.0556 - val_mean_squared_error: 0.0106 - lr: 0.0010\nEpoch 17/60\n500/500 [==============================] - 223s 445ms/step - loss: 0.0552 - mean_squared_error: 0.0105 - val_loss: 0.0557 - val_mean_squared_error: 0.0106 - lr: 0.0010\nEpoch 18/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0553 - mean_squared_error: 0.0105 - val_loss: 0.0569 - val_mean_squared_error: 0.0110 - lr: 0.0010\nEpoch 19/60\n500/500 [==============================] - 221s 443ms/step - loss: 0.0549 - mean_squared_error: 0.0104 - val_loss: 0.0551 - val_mean_squared_error: 0.0104 - lr: 0.0010\nEpoch 20/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0551 - mean_squared_error: 0.0104 - val_loss: 0.0550 - val_mean_squared_error: 0.0104 - lr: 0.0010\nEpoch 21/60\n500/500 [==============================] - 222s 443ms/step - loss: 0.0546 - mean_squared_error: 0.0103 - val_loss: 0.0557 - val_mean_squared_error: 0.0106 - lr: 0.0010\nEpoch 22/60\n500/500 [==============================] - 222s 443ms/step - loss: 0.0545 - mean_squared_error: 0.0102 - val_loss: 0.0547 - val_mean_squared_error: 0.0103 - lr: 0.0010\nEpoch 23/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0541 - mean_squared_error: 0.0102 - val_loss: 0.0558 - val_mean_squared_error: 0.0107 - lr: 0.0010\nEpoch 24/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0541 - mean_squared_error: 0.0101 - val_loss: 0.0544 - val_mean_squared_error: 0.0101 - lr: 0.0010\nEpoch 25/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0542 - mean_squared_error: 0.0102 - val_loss: 0.0554 - val_mean_squared_error: 0.0105 - lr: 0.0010\nEpoch 26/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0535 - mean_squared_error: 0.0100 - val_loss: 0.0549 - val_mean_squared_error: 0.0103 - lr: 0.0010\nEpoch 27/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0535 - mean_squared_error: 0.0099 - val_loss: 0.0555 - val_mean_squared_error: 0.0105 - lr: 0.0010\nEpoch 28/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0535 - mean_squared_error: 0.0099 - val_loss: 0.0552 - val_mean_squared_error: 0.0104 - lr: 0.0010\nEpoch 29/60\n500/500 [==============================] - 223s 446ms/step - loss: 0.0539 - mean_squared_error: 0.0101 - val_loss: 0.0539 - val_mean_squared_error: 0.0101 - lr: 0.0010\nEpoch 30/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0524 - mean_squared_error: 0.0096 - val_loss: 0.0528 - val_mean_squared_error: 0.0098 - lr: 1.0000e-04\nEpoch 31/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0522 - mean_squared_error: 0.0095 - val_loss: 0.0522 - val_mean_squared_error: 0.0095 - lr: 1.0000e-04\nEpoch 32/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0522 - mean_squared_error: 0.0095 - val_loss: 0.0529 - val_mean_squared_error: 0.0097 - lr: 1.0000e-04\nEpoch 33/60\n500/500 [==============================] - 223s 445ms/step - loss: 0.0517 - mean_squared_error: 0.0094 - val_loss: 0.0535 - val_mean_squared_error: 0.0098 - lr: 1.0000e-04\nEpoch 34/60\n500/500 [==============================] - 223s 445ms/step - loss: 0.0522 - mean_squared_error: 0.0096 - val_loss: 0.0521 - val_mean_squared_error: 0.0094 - lr: 1.0000e-04\nEpoch 35/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0519 - mean_squared_error: 0.0094 - val_loss: 0.0530 - val_mean_squared_error: 0.0097 - lr: 1.0000e-04\nEpoch 36/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0518 - mean_squared_error: 0.0094 - val_loss: 0.0524 - val_mean_squared_error: 0.0096 - lr: 1.0000e-04\nEpoch 37/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0518 - mean_squared_error: 0.0094 - val_loss: 0.0521 - val_mean_squared_error: 0.0094 - lr: 1.0000e-05\nEpoch 38/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0515 - mean_squared_error: 0.0093 - val_loss: 0.0534 - val_mean_squared_error: 0.0097 - lr: 1.0000e-05\nEpoch 39/60\n500/500 [==============================] - 222s 445ms/step - loss: 0.0515 - mean_squared_error: 0.0093 - val_loss: 0.0529 - val_mean_squared_error: 0.0097 - lr: 1.0000e-05\nEpoch 40/60\n500/500 [==============================] - 223s 445ms/step - loss: 0.0511 - mean_squared_error: 0.0092 - val_loss: 0.0521 - val_mean_squared_error: 0.0094 - lr: 1.0000e-05\nEpoch 41/60\n500/500 [==============================] - 223s 446ms/step - loss: 0.0516 - mean_squared_error: 0.0093 - val_loss: 0.0526 - val_mean_squared_error: 0.0096 - lr: 1.0000e-05\nEpoch 42/60\n500/500 [==============================] - 223s 446ms/step - loss: 0.0517 - mean_squared_error: 0.0093 - val_loss: 0.0531 - val_mean_squared_error: 0.0097 - lr: 1.0000e-06\nEpoch 43/60\n500/500 [==============================] - 223s 445ms/step - loss: 0.0515 - mean_squared_error: 0.0093 - val_loss: 0.0521 - val_mean_squared_error: 0.0094 - lr: 1.0000e-06\nEpoch 44/60\n500/500 [==============================] - 222s 444ms/step - loss: 0.0514 - mean_squared_error: 0.0093 - val_loss: 0.0525 - val_mean_squared_error: 0.0096 - lr: 1.0000e-06\n",
          "output_type": "stream"
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7b25fdc8f160>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "GF5YTvnD3gKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_gen_loss = model.evaluate(test_gen, steps=len(testset) // batch_size)\n",
        "print(\"Mean Squared Error on the test set:\", test_gen_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-09T21:55:09.039752Z",
          "iopub.execute_input": "2023-07-09T21:55:09.040118Z",
          "iopub.status.idle": "2023-07-09T21:55:19.321224Z",
          "shell.execute_reply.started": "2023-07-09T21:55:09.040088Z",
          "shell.execute_reply": "2023-07-09T21:55:19.318433Z"
        },
        "trusted": true,
        "id": "12iIBjzqtJLL",
        "outputId": "24a23789-fcd0-44fd-fb26-b3be7ea21ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "62/62 [==============================] - 10s 157ms/step - loss: 0.0406 - mean_squared_error: 0.0089\nMean Squared Error on the test set: [0.04060353711247444, 0.00888848677277565]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose to use this model because it generated a lower Mean Squared Error (under 0.01), a good predicted image (the result is optimal only in the case of overlapping numbers) and, compared to other models I tested it is a good compromise between execution time (related to the number of parameters used), predicted image quality and mean squared error. It takes less time and has a reduced number of total parameters thus reducing the overall cost of the network."
      ],
      "metadata": {
        "id": "z6X3O-KMeLs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicted Output"
      ],
      "metadata": {
        "id": "ru6I0E-f3Us3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sample batch of test data\n",
        "sample_x,sample_y=next(test_gen)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "new_prediction=model.predict(sample_x)\n",
        "\n",
        "# Print the shape of the new predictions\n",
        "print(new_prediction.shape)\n",
        "\n",
        "# Prepare a list of images for visualization\n",
        "all = [sample_x[0,i,:,:,:] for i in range(3)]+[sample_y[0,0,:,:,0]]\n",
        "\n",
        "# Display the list of images using the show_list function\n",
        "show_list(all)\n",
        "\n",
        "# Prepare a new list of images with the predicted output\n",
        "all = [sample_x[0,i,:,:,:] for i in range(3)]+[new_prediction[0,0,:,:,0]]\n",
        "\n",
        "# Display the list of images with the predicted output\n",
        "show_list(all)"
      ],
      "metadata": {
        "id": "I3MgP84rjLdO",
        "execution": {
          "iopub.status.busy": "2023-07-09T20:58:16.791235Z",
          "iopub.execute_input": "2023-07-09T20:58:16.792253Z",
          "iopub.status.idle": "2023-07-09T20:58:18.138591Z",
          "shell.execute_reply.started": "2023-07-09T20:58:16.792211Z",
          "shell.execute_reply": "2023-07-09T20:58:18.137646Z"
        },
        "trusted": true,
        "outputId": "dbdce8d1-7254-4349-f685-9d386ab8aa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1/1 [==============================] - 0s 31ms/step\n(16, 1, 64, 64, 1)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x4000 with 4 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x4000 with 4 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some previous attempts"
      ],
      "metadata": {
        "id": "UtT45AfOuKmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I tried to stack a combination of Conv2D and LSTM layers. The Conv2D layers capture spatial information from the input frames, while the LSTM layer captures the temporal dependencies between frames. The final Conv2D layer with a sigmoid activation is used to generate the predicted frame. But in this situation I have obtained an higher value of the mean squared error.\n",
        "\n",
        "- I tried to change the number of batch_size but I have obtained a worst result\n",
        "\n",
        "- I have tried to implement the Convolutional LSTM model in a sequential way.\n",
        "The result provided by this architecture was similar to the one of that I have decided to use. The code defines the architecture of a model using the Keras Sequential API that allows to stack layers sequentially, making it easy to build models layer by layer. The Sequential model is used to stack these layers in the specified order to create the desired model architecture. Adding multiple layers in the model can potentially help in capturing more complex patterns and representations in the data. Each additional layer allows the model to learn and extract higher-level features from the input. I have tried this model with several combination of the kernel size.\n",
        "> I also performed all the attempts described below with the chosen functional model, I don't report all the codes because it would be unnecessarily verbose (they change only by the number of layers).\n",
        ">> For example I have tried a 9x9 before the 7x7 (very high computational cost given by the large number of parameters used (over 4 million parameters), but without major improvements in the value of the mean square error), a 9x9 before the 5x5 without the 7x7 (In this case I have obtained a good mean square error, almost equal to the one of the model I have considered but with an higher computational cost due to the higher number of parameters (2,793,665 respect to the 2,261,185 of the 7x7 model)), another 3x3 after the 5x5 (with and without the 7x7 layer). In the model with the two ConvLSTM2D layers with a kernel size of 3x3 (without the 7x7 layer) in the code serve to process the data sequences in more detail and capture finer spatial features (I have obtainded a good MSE on the test set (little bit higher\n",
        "(never under 0.01 MSE with 40 epochs) that the one of the model I have considerd)."
      ],
      "metadata": {
        "id": "7pnFSTv0OpCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "\n",
        "# Constructing the model using a Sequential API\n",
        "model1 = keras.Sequential([\n",
        "    # First ConvLSTM2D layer with batch normalization\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=64,\n",
        "        kernel_size=(7, 7),\n",
        "        padding=\"same\",\n",
        "        return_sequences=True,\n",
        "        activation=\"relu\",\n",
        "        input_shape=(None, 64, 64, 1)\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Second ConvLSTM2D layer with batch normalization\n",
        "    layers.ConvLSTM2D(\n",
        "      filters=64,\n",
        "      kernel_size=(5, 5),\n",
        "      padding=\"same\",\n",
        "      return_sequences=True,\n",
        "      activation=\"relu\",\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Third ConvLSTM2D layer with batch normalization\n",
        "    layers.ConvLSTM2D(filters=64,\n",
        "      kernel_size=(3, 3),\n",
        "      padding=\"same\",\n",
        "      return_sequences=True,\n",
        "      activation=\"relu\",\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Fourth ConvLSTM2D layer\n",
        "    layers.ConvLSTM2D(filters=64,\n",
        "      kernel_size=(1, 1),\n",
        "      padding=\"same\",\n",
        "      return_sequences=True,\n",
        "      activation=\"relu\",\n",
        "    ),\n",
        "\n",
        "    # Conv3D layer for spatiotemporal outputs\n",
        "    layers.Conv3D(\n",
        "      filters=1,\n",
        "      kernel_size=(3, 3, 3),\n",
        "      activation=\"sigmoid\",\n",
        "      padding=\"same\"\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "5DBzz3tzGbeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Another model that I have tried is the following in which I have obtained MSE=0.0095 and a good prediction:"
      ],
      "metadata": {
        "id": "gnS1MZuYtJLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (None, 64, 64, 1)\n",
        "\n",
        "# Input layer\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "# First ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(9, 9),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Second ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(5, 5),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Third ConvLSTM2D layer with batch normalization\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(3, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Fourth ConvLSTM2D layer with batch normalization\n",
        "\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=64,\n",
        "    kernel_size=(1, 1),\n",
        "    padding=\"same\",\n",
        "    return_sequences=True,\n",
        "    activation=\"relu\"\n",
        ")(x)\n",
        "\n",
        "# Conv3D layer for spatiotemporal outputs\n",
        "x = layers.Conv3D(\n",
        "    filters=1,\n",
        "    kernel_size=(3, 3, 3),\n",
        "    activation=\"sigmoid\",\n",
        "    padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "# Lambda layer to select the last frame of each sequence\n",
        "x = layers.Lambda(lambda x: x[:, -1, :, :, :])(x)\n",
        "\n",
        "# Reshape layer to adjust the shape of the tensor\n",
        "output = layers.Reshape((1, 64, 64, 1))(x)\n",
        "\n",
        "# Create the model\n",
        "model2 = keras.models.Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "i7QVHLpmtJLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I have tried also a different approach with a stack of Conv2D and MaxPooling layers, but I have obtained a worst result:"
      ],
      "metadata": {
        "id": "tsREW1X7Gndw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.UpSampling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.UpSampling2D((2, 2)),\n",
        "    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
        "])"
      ],
      "metadata": {
        "id": "5nyZlrFxc3fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Another model that I have tried is the following (I am attaching only the modified part of the code, the fit function remained unchanged. I have also tried this model in a non sequetial way (the code is similar to the following one)) in which I have increased the number of filters for the ConvLSTM2D layers and added a fourth ConvLSTM2D layer with 256 filters because, generally, increasing the number of filters can help the model capture more complex representations of the data.\n",
        "I have used a smaller kernel size (3x3) for the subsequent ConvLSTM2D layers. This can allow the model to consider finer details in the input data.\n",
        "> The obtained value of mean squared error is almost identical to the 3 ConvLSTM2D model (with 5x5,3x3,1x1 layers), the only difference is that this model need higher time to be computed, since it work with Total params: 6,030,849 instead of Total params: 746,689 given by the 3 ConvLSTM2D model."
      ],
      "metadata": {
        "id": "DiVbSwQcc1hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = keras.Sequential([\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=64,\n",
        "        kernel_size=(5, 5),\n",
        "        padding=\"same\",\n",
        "        return_sequences=True,\n",
        "        activation=\"relu\",\n",
        "        input_shape=(None, 64, 64, 1)\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        return_sequences=True,\n",
        "        activation=\"relu\"\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        return_sequences=True,\n",
        "        activation=\"relu\"\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        return_sequences=True,\n",
        "        activation=\"relu\"\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv3D(\n",
        "        filters=1,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        activation=\"sigmoid\",\n",
        "        padding=\"same\"\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "qZagCXUSRt7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}